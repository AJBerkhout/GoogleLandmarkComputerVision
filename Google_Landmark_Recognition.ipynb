{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Google Landmark Recognition",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": false,
        "trusted": true,
        "id": "-Ama-IecGIds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "137a7d49-d568-4c25-ec86-3ce84d2b9e3e"
      },
      "source": [
        "%tensorflow_version 1.14\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import keras\n",
        "from keras.applications import ResNet50\n",
        "from keras.layers import Layer\n",
        "from keras import regularizers\n",
        "from keras.engine.topology import Input\n",
        "from keras.layers import Activation, Add, BatchNormalization, Concatenate, Conv2D, Dense, Flatten, GlobalMaxPooling2D, \\\n",
        "    GlobalAveragePooling2D, Lambda, MaxPooling2D, Reshape\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import os\n",
        "from shutil import copyfile\n",
        "\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import tarfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.utils import Sequence\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import urllib\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "import json\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.models import load_model\n",
        "from google.colab import files\n",
        "# src = list(files.upload().values())[0]\n",
        "# open('keras-vgg16-places365.py','wb').write(src)\n",
        "# os.chdir(\"/kaggle/input/keras-vgg16-places365/\")\n",
        "from vgg16_places_365 import VGG16_Places365\n",
        "# os.chdir(\"/kaggle/working/\")\n",
        "\n",
        "\n",
        "\n",
        "def check_size(url):\n",
        "    \"\"\"\n",
        "    Helper method to check the size of the file from the url\n",
        "    \"\"\"\n",
        "    r = requests.get(url, stream=True)\n",
        "    return int(r.headers['Content-Length'])\n",
        "\n",
        "\n",
        "def download_file(url, filename, bar=True):\n",
        "    \"\"\"\n",
        "    Helper method handling downloading large files from `url` to `filename`. Returns a pointer to `filename`.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        chunkSize = 1024\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(filename, 'wb') as f:\n",
        "            if bar:\n",
        "                pbar = tqdm(unit=\"B\", total=int(r.headers['Content-Length']))\n",
        "            for chunk in r.iter_content(chunk_size=chunkSize):\n",
        "                if chunk:  # filter out keep-alive new chunks\n",
        "                    if bar:\n",
        "                        pbar.update(len(chunk))\n",
        "                    f.write(chunk)\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return\n",
        "\n",
        "\n",
        "def download_image_cv2_urllib(url):\n",
        "    \"\"\"\n",
        "    Modifying the url to download the 360p or 720p version actually slows it down.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        resp = urllib.request.urlopen(url)\n",
        "        foo = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "        foo = cv2.imdecode(foo, cv2.IMREAD_COLOR)\n",
        "        foo = cv2.resize(foo, (192, 192), interpolation=cv2.INTER_AREA)\n",
        "        foo = cv2.cvtColor(foo, cv2.COLOR_BGR2RGB)\n",
        "        return foo\n",
        "    except:\n",
        "        return np.array([])\n",
        "    \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def accuracy_class(y_true, y_pred):\n",
        "    true = K.argmax(y_true, axis=1)\n",
        "    pred = K.argmax(y_pred, axis=1)\n",
        "    matches = K.equal(true, pred)\n",
        "    return K.mean(matches)\n",
        "\n",
        "\n",
        "def accuracy_class_numpy(y_true, y_pred):\n",
        "    true = np.argmax(y_true, axis=1)\n",
        "    pred = np.argmax(y_pred, axis=1)\n",
        "    matches = true == pred\n",
        "    return np.mean(matches)\n",
        "\n",
        "\n",
        "def getConfidence(y_pred):\n",
        "    y_pred_max = np.reshape(np.amax(y_pred, axis=1), (y_pred.shape[0], 1))\n",
        "\n",
        "    top5 = np.zeros((y_pred.shape[0], 5))\n",
        "    max_indices = np.argsort(y_pred, axis=1)[:, ::-1][:, :5]\n",
        "    for i in range(y_pred.shape[0]):\n",
        "        top5[i, :] = y_pred[i, max_indices[i, :]]\n",
        "    diff = y_pred_max - top5\n",
        "    weights = np.array([[0., 0.35, 0.28, 0.22, 0.15]])\n",
        "    weighted_diffs = diff * weights\n",
        "    return np.sum(weighted_diffs, axis=1)\n",
        "\n",
        "\n",
        "def getOrder(y_pred):\n",
        "    summ = getConfidence(y_pred)\n",
        "    summ_indices = np.argsort(summ)[::-1]\n",
        "    return summ_indices\n",
        "\n",
        "\n",
        "def MAP_numpy(y_true, y_pred):\n",
        "    true = np.argmax(y_true, axis=1)\n",
        "    pred = np.argmax(y_pred, axis=1)\n",
        "    matches = true == pred\n",
        "\n",
        "    order = getOrder(y_pred)\n",
        "    orderedMatches = matches[order]\n",
        "\n",
        "    correct = 0.\n",
        "    summ = 0.\n",
        "    for i in range(y_true.shape[0]):\n",
        "        correct += int(orderedMatches[i])\n",
        "        summ += (correct / (i + 1)) * int(orderedMatches[i])\n",
        "    return summ / y_true.shape[0]\n",
        "\n",
        "\n",
        "def validateMAP(model, valid_x, valid_y):\n",
        "    \"\"\"\n",
        "    :param model: the model to use\n",
        "    :param valid_x: numpy array of validation images\n",
        "    :param valid_y: list of landmarks of the validation images\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    N = valid_x.shape[0]\n",
        "    batchsize = 1000\n",
        "    conf_list = []\n",
        "    y_pred_list = []\n",
        "    validM = N // batchsize + int(N % batchsize > 0)\n",
        "    for i in range(validM):\n",
        "        preds = model.predict(valid_x[i * batchsize:min(N, (i + 1) * batchsize), :, :, :])\n",
        "        conf = list(np.amax(preds, axis=1))\n",
        "        conf_list.extend(conf)\n",
        "        y_pred = list(np.argmax(preds, axis=1))\n",
        "        y_pred_list.extend(y_pred)\n",
        "\n",
        "    matches = list(np.array(y_pred_list) == np.array(valid_y))\n",
        "\n",
        "    order = list(np.argsort(conf_list)[::-1])\n",
        "    orderedMatches = [matches[o] for o in order]\n",
        "\n",
        "    correct = 0.\n",
        "    summ = 0.\n",
        "    for i in range(len(orderedMatches)):\n",
        "        correct += int(orderedMatches[i])\n",
        "        summ += (correct / (i + 1)) * int(orderedMatches[i])\n",
        "\n",
        "    print(np.sum(matches))\n",
        "    print(correct)\n",
        "    print(summ / len(orderedMatches))\n",
        "\n",
        "\n",
        "class DataGen(Sequence):\n",
        "    \"\"\"\n",
        "    This generator downloads one tar file at each epoch. Extracts and selects the valid images from it to\n",
        "    form batches. And after the epoch is complete, deletes the files to free up space.\n",
        "    \"\"\"\n",
        "    def __init__(self, valid_ids_dict, num_classes, start=10, batch_size=128, steps=10, verbose=1):\n",
        "\n",
        "        self.valid_ids_dict = valid_ids_dict # dict of image ids to landmarks {image_id: landmark_id}\n",
        "        self.NUM_CLASSES = num_classes # number of valid classes to consider\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.steps = steps # should be equal to the number of epochs\n",
        "        self.images = []\n",
        "        self.landmarks = []\n",
        "        self.tar_idx = start\n",
        "        self.epoch_init()\n",
        "\n",
        "    def epoch_init(self):\n",
        "        self.all_images = []\n",
        "        self.all_landmarks = []\n",
        "\n",
        "        if self.tar_idx < 10:\n",
        "            tarfilestr = \"00\" + str(self.tar_idx)\n",
        "        elif self.tar_idx < 100:\n",
        "            tarfilestr = \"0\" + str(self.tar_idx)\n",
        "        else:\n",
        "            tarfilestr = str(self.tar_idx)\n",
        "\n",
        "        download_file(\"https://s3.amazonaws.com/google-landmark/train/images_{}.tar\".format(tarfilestr), \"images.tar\",\n",
        "                      bar=False)\n",
        "        #print(os.listdir())\n",
        "        tar = tarfile.open('images.tar')\n",
        "        tar.extractall(\"imagesfolder\")\n",
        "        tar.close()\n",
        "\n",
        "        self.total = self.pickfiles(\"imagesfolder\")\n",
        "        self.tar_idx += 1\n",
        "        print(\"tar\", self.tar_idx - 1, \"total:\", self.total)\n",
        "\n",
        "    def pickfiles(self, dirr):\n",
        "        count = 0\n",
        "        for f in os.listdir(dirr):\n",
        "            if os.path.isfile(dirr + \"/\" + f):\n",
        "                if f[:-4] in self.valid_ids_dict:\n",
        "                    self.all_images.append(dirr + \"/\" + f)\n",
        "                    self.all_landmarks.append(self.valid_ids_dict[f[:-4]])\n",
        "                    count += 1\n",
        "            else:\n",
        "                count += self.pickfiles(dirr + \"/\" + f)\n",
        "        return count\n",
        "\n",
        "    def normalize(self, data):\n",
        "        return data / 255 - 0.5\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path_list = self.all_images[index * self.batch_size:min(self.total, (index + 1)) * self.batch_size]\n",
        "        class_list = self.all_landmarks[index * self.batch_size:min(self.total, (index + 1)) * self.batch_size]\n",
        "\n",
        "        if len(image_path_list) == 0:\n",
        "            image_path_list = self.all_images[:self.batch_size]\n",
        "            class_list = self.all_landmarks[:self.batch_size]\n",
        "\n",
        "        images = []\n",
        "        y_list = []\n",
        "        for ix in range(len(image_path_list)):\n",
        "            try:\n",
        "                image_path = image_path_list[ix]\n",
        "                im = cv2.imread(image_path)\n",
        "                im = cv2.resize(im, (192, 192), interpolation=cv2.INTER_AREA)\n",
        "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "                if im.shape == (192, 192, 3):\n",
        "                    images.append(im)\n",
        "                    y_list.append(class_list[ix])\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        x = np.array(images)\n",
        "        y = np.zeros((len(y_list), self.NUM_CLASSES))\n",
        "\n",
        "        for i in range(len(y_list)):\n",
        "            y[i, y_list[i]] = 1.\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.steps -= 1\n",
        "        os.unlink(\"images.tar\")\n",
        "        shutil.rmtree(\"imagesfolder\")\n",
        "        if self.steps > 0:\n",
        "            self.epoch_init()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total // self.batch_size + int(self.total % self.batch_size > 0)\n",
        "\n",
        "\n",
        "class DataGenURLVersion(Sequence):\n",
        "    \"\"\"';'\n",
        "    This generator uses the image urls from the train dataset to form batches\n",
        "    and downloads each image individually. It will be approx 10 times slower than above version.\n",
        "    \"\"\"\n",
        "    def __init__(self, valid_urls_dict, num_classes, data, batch_size=24, verbose=1):\n",
        "        self.batch_size = batch_size\n",
        "        self.data_urls = data\n",
        "        self.NUM_CLASSES = num_classes # number of classes\n",
        "        self.valid_urls_dict = valid_urls_dict # dict of url and corresponding landmark {image_url: landmark}\n",
        "\n",
        "    def normalize(self, data):\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_urls = random.sample(self.data_urls, self.batch_size)\n",
        "\n",
        "        output = []\n",
        "        y_classes = []\n",
        "        for url in batch_urls:\n",
        "            im = download_image_cv2_urllib(url)\n",
        "            if im.size != 0:\n",
        "                output.append(im)\n",
        "                y_classes.append(self.valid_urls_dict[url.split(\"/\")[-1]])\n",
        "\n",
        "        x = np.array(output)\n",
        "        y = np.zeros((len(output), self.NUM_CLASSES))\n",
        "\n",
        "        for i in range(len(y_classes)):\n",
        "            y[i, y_classes[i]] = 1.\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        return\n",
        "\n",
        "    def __len__(self):\n",
        "        # return len(valid_urls_list) // self.batch_size\n",
        "        return 10\n",
        "\n",
        "    \n",
        "\n",
        "# ------------------------------ form the dataset ------------------------------ #\n",
        "\n",
        "download_file(\"https://s3.amazonaws.com/google-landmark/metadata/train.csv\", \"train.csv\")\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "print(train.head())\n",
        "print(train.shape)\n",
        "print(\"Number of classes {}\".format(len(train.landmark_id.unique())))\n",
        "\n",
        "\n",
        "\n",
        "NUM_THRESHOLD = 20\n",
        "\n",
        "counts = dict(Counter(train['landmark_id']))\n",
        "landmarks_dict = {x:[] for x in train.landmark_id.unique() if counts[x] >= NUM_THRESHOLD and x != 138982}\n",
        "NUM_CLASSES = len(landmarks_dict)\n",
        "print(\"Total number of valid classes: {}\".format(NUM_CLASSES))\n",
        "\n",
        "i = 0\n",
        "landmark_to_idx = {}\n",
        "idx_to_landmark = []\n",
        "for k in landmarks_dict:\n",
        "    landmark_to_idx[k] = i\n",
        "    idx_to_landmark.append(k)\n",
        "    i += 1\n",
        "\n",
        "all_ids = train['id'].tolist()\n",
        "all_landmarks = train['landmark_id'].tolist()\n",
        "valid_ids_dict = {x[0].split(\"/\")[-1]:landmark_to_idx[x[1]] for x in zip(all_ids, all_landmarks) if x[1] in landmarks_dict}\n",
        "valid_ids_list = [x[0] for x in zip(all_ids, all_landmarks) if x[1] in landmarks_dict]\n",
        "\n",
        "NUM_EXAMPLES = len(valid_ids_list)\n",
        "print(\"Total number of valid examples: {}\".format(NUM_EXAMPLES))\n",
        "\n",
        "\n",
        "# ------------------------------------- validation ------------------------------------------------- #\n",
        "\n",
        "download_file(\"https://s3.amazonaws.com/google-landmark/train/images_001.tar\", \"validation.tar\", bar=False)\n",
        "tar = tarfile.open('validation.tar')\n",
        "tar.extractall(\"validation\")\n",
        "tar.close()\n",
        "\n",
        "os.unlink(\"validation.tar\")\n",
        "\n",
        "print(os.listdir())\n",
        "\n",
        "validation_images_paths = []\n",
        "validation_landmarks = []\n",
        "\n",
        "\n",
        "def pickfiles(dirr):\n",
        "    count = 0\n",
        "    for f in os.listdir(dirr):\n",
        "        if os.path.isfile(dirr + \"/\" + f):\n",
        "            if f[:-4] in valid_ids_dict:\n",
        "                validation_images_paths.append(dirr + \"/\" + f)\n",
        "                validation_landmarks.append(valid_ids_dict[f[:-4]])\n",
        "                count += 1\n",
        "        else:\n",
        "            count += pickfiles(dirr + \"/\" + f)\n",
        "    return count\n",
        "\n",
        "\n",
        "total = pickfiles(\"validation\")\n",
        "print(\"total:\", total)\n",
        "\n",
        "validation_images = []\n",
        "\n",
        "for image_path in validation_images_paths:\n",
        "    im = cv2.imread(image_path)\n",
        "    im = cv2.resize(im, (192, 192), interpolation=cv2.INTER_AREA)\n",
        "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "    validation_images.append(im)\n",
        "\n",
        "valid_x = np.array(validation_images)\n",
        "valid_y = np.zeros((len(validation_landmarks), NUM_CLASSES))\n",
        "\n",
        "for i in range(len(validation_landmarks)):\n",
        "    valid_y[i, validation_landmarks[i]] = 1.\n",
        "\n",
        "shutil.rmtree(\"validation\")\n",
        "del validation_images\n",
        "\n",
        "# ------------------------------------ model ----------------------------------------- #\n",
        "\n",
        "res = ResNet50(include_top=False, weights='imagenet', input_shape=(192, 192, 3))\n",
        "\n",
        "# making all the layers trainable\n",
        "for layer in res.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "out = GlobalMaxPooling2D()(res.output)\n",
        "out = Dense(NUM_CLASSES, activation='softmax')(out)\n",
        "model = Model(res.input, out)\n",
        "model.summary()\n",
        "# ---------------------------------- clear block ------------------------------------- #\n",
        "\n",
        "# folder = \"./\"\n",
        "# for file in os.listdir(folder):\n",
        "#     file_path = os.path.join(folder, file)\n",
        "#     if os.path.isfile(file_path):\n",
        "#         os.unlink(file_path)\n",
        "#     else:\n",
        "#         import shutil\n",
        "#         shutil.rmtree(file_path)\n",
        "\n",
        "#gc.collect()\n",
        "\n",
        "# ----------------------------------- training ---------------------------------------- #\n",
        "\n",
        "EPOCHS = 1\n",
        "opt = Adam(0.0002)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
        "model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=10, batch_size=64,steps=EPOCHS),\n",
        "                   epochs=EPOCHS,\n",
        "                   validation_data = [valid_x, valid_y],\n",
        "                   use_multiprocessing=True,\n",
        "                   workers=8,\n",
        "                   verbose=2)\n",
        "\n",
        "EPOCHS = 1\n",
        "opt = Adam(0.0001)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
        "model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=180, batch_size=48,steps=EPOCHS),\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data = [valid_x, valid_y],\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    verbose=2)\n",
        "\n",
        "EPOCHS = 1\n",
        "opt = Adam(0.00004)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
        "model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=340, batch_size=48,steps=EPOCHS),\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data = [valid_x, valid_y],\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    verbose=2)\n",
        "\n",
        "EPOCHS = 1\n",
        "opt = Adam(0.00002)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
        "model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=390, batch_size=48,steps=EPOCHS),\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data = [valid_x, valid_y],\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    verbose=2)\n",
        "\n",
        "# ------------------------------------------- GAP metric validation -------------------------------------- #\n",
        "\n",
        "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "print(\"model saved\")\n",
        "del model  # deletes the existing model\n",
        "\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "model = load_model('my_model.h5', custom_objects={\n",
        "        \"accuracy_class\": accuracy_class\n",
        "    })\n",
        "print(\"loaded model\")\n",
        "#gap = validateMAP()\n",
        "#print(gap)\n",
        "\n",
        "# ------------------------------------------- testset ------------------------------------------------- #\n",
        "\n",
        "download_file(\"https://s3.amazonaws.com/google-landmark/metadata/test.csv\", \"test.csv\")\n",
        "testdf = pd.read_csv(\"test.csv\")\n",
        "print(testdf.head())\n",
        "\n",
        "testids = testdf['id'].tolist()\n",
        "print(len(testids))\n",
        "\n",
        "# -------------------------------------------- prediction ------------------------------------------------ #\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import time\n",
        "\n",
        "tm = time.time()\n",
        "\n",
        "final_ids = []\n",
        "final_conf = []\n",
        "final_preds = []\n",
        "\n",
        "tar_images = []\n",
        "tar_ids = []\n",
        "    \n",
        "    \n",
        "def pickfiles(dirr):\n",
        "    count = 0\n",
        "    for f in os.listdir(dirr):\n",
        "        if os.path.isfile(dirr + \"/\" + f):\n",
        "            tar_images.append(dirr + \"/\" + f)\n",
        "            tar_ids.append(f[:-4])\n",
        "            count += 1\n",
        "        else:\n",
        "            count += pickfiles(dirr + \"/\" + f)\n",
        "    return count\n",
        "\n",
        "\n",
        "for tar in range(20):\n",
        "    if tar < 10:\n",
        "        tar_id = \"00\" + str(tar)\n",
        "    else:\n",
        "        tar_id = \"0\" + str(tar)\n",
        "\n",
        "    tar_images = []\n",
        "    tar_ids = []\n",
        "\n",
        "    download_file(\"https://s3.amazonaws.com/google-landmark/test/images_{}.tar\".format(tar_id), \"images.tar\", bar=False)\n",
        "    tar = tarfile.open('images.tar')\n",
        "    tar.extractall(\"imagesfolder\")\n",
        "    tar.close()\n",
        "\n",
        "    os.unlink(\"images.tar\")\n",
        "\n",
        "    total = pickfiles(\"imagesfolder\")\n",
        "    print(tar, total, len(tar_ids))\n",
        "        \n",
        "    \n",
        "    N = total\n",
        "    batchsize = 1000\n",
        "    conf_list = []\n",
        "    y_pred_list = []\n",
        "    validM = N // batchsize + int(N % batchsize > 0)\n",
        "    \n",
        "    # Placeholders for predictions\n",
        "\n",
        "\n",
        "    # Places365 Model\n",
        "    discrim_model = VGG16_Places365(weights='places')\n",
        "    class_information = pd.read_csv('categories_places365_extended.csv')\n",
        "    topn = 5\n",
        "    \n",
        "    for i in range(validM):\n",
        "        temp = tar_images[i * batchsize:min(N, (i + 1) * batchsize)]\n",
        "        batch_images = []\n",
        "        batch_images_2 = []\n",
        "        for t in temp:\n",
        "            im = cv2.imread(t)\n",
        "            im = cv2.resize(im, (192, 192), interpolation=cv2.INTER_AREA)\n",
        "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "            batch_images.append(im)\n",
        "        for t in temp:\n",
        "            im = cv2.imread(t)\n",
        "            im = cv2.resize(im, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "            batch_images_2.append(im)\n",
        "        p0, p1, p2 = [], [], []\n",
        "        isLandmark = []\n",
        "        batch_images = np.array(batch_images)\n",
        "        \n",
        "        \n",
        "        # Loop through all images\n",
        "        for (i, image) in enumerate(batch_images_2):\n",
        "    \n",
        "            # Predict Top N Image Classes\n",
        "            image = np.expand_dims(image, 0)\n",
        "            topn_preds = np.argsort(discrim_model.predict(image)[0])[::-1][0:topn]\n",
        "            \n",
        "            p0 = topn_preds[0]\n",
        "            p1 = topn_preds[1]\n",
        "            p2 = topn_preds[2]\n",
        "            p0_landmark = class_information.loc[p0, ['io']][0] # p0.map(.set_index('class')['io'].replace({1:False, 2:True}))\n",
        "            p1_landmark = class_information.loc[p0, ['io']][0]#p1.map(class_information.set_index('class')['io'].replace({1:False, 2:True}))\n",
        "            p2_landmark = class_information.loc[p0, ['io']][0]#p2.map(class_information.set_index('class')['io'].replace({1:False, 2:True}))\n",
        "            num_landmark = 0\n",
        "            if (p0_landmark == 2): \n",
        "                num_landmark += 1\n",
        "            if (p1_landmark == 2):\n",
        "                num_landmark += 1\n",
        "            if (p2_landmark == 2): \n",
        "                num_landmark += 1\n",
        "            isLandmark.append(.01 + .33 * num_landmark)\n",
        "            \n",
        "        \n",
        "        preds = model.predict(batch_images)\n",
        "        \n",
        "        conf = list(np.amax(preds, axis=1))\n",
        "        conf = [c * isLandmark[i] for (i, c) in enumerate(conf)]\n",
        "        conf_list.extend(conf)\n",
        "        y_pred = list(np.argmax(preds, axis=1))\n",
        "                  \n",
        "        \n",
        "        y_pred_list.extend(y_pred)\n",
        "\n",
        "    final_preds.extend(y_pred_list)\n",
        "    final_conf.extend(conf_list)\n",
        "    final_ids.extend(tar_ids)\n",
        "    shutil.rmtree(\"imagesfolder\")\n",
        "\n",
        "print(\"time\", time.time() - tm)\n",
        "print(len(final_preds))\n",
        "\n",
        "\n",
        "# --------------------------------------- submission -------------------------------------- #\n",
        "\n",
        "out = []\n",
        "for i in range(len(final_preds)):\n",
        "    idx = final_preds[i]\n",
        "    out.append(str(idx_to_landmark[idx]) + \" \" + str(round(final_conf[i], 10)))\n",
        "\n",
        "print(out[:5])\n",
        "\n",
        "outdf = pd.DataFrame({\"id\": final_ids, \"landmarks\": out})\n",
        "print(outdf.head())\n",
        "\n",
        "outdf.to_csv(\"submissions.csv\", index=False)\n",
        "\n",
        "# ---------------------------------------- the end ----------------------------------------- #"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.14`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/525832518 [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 104448/525832518 [00:00<13:14, 661863.31B/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 522240/525832518 [00:00<10:03, 870726.50B/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 1856512/525832518 [00:00<07:16, 1201437.77B/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 5228544/525832518 [00:00<05:07, 1690523.68B/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|▏         | 7813120/525832518 [00:00<03:40, 2349177.81B/s]\u001b[A\u001b[A\n",
            " 40%|████      | 210882560/525832518 [00:24<00:09, 32458039.93B/s]\u001b[A\n",
            "\n",
            "  2%|▏         | 11523072/525832518 [00:00<02:38, 3253760.52B/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 15537152/525832518 [00:00<01:54, 4452699.90B/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 19649536/525832518 [00:00<01:24, 6009093.03B/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 23696384/525832518 [00:01<01:03, 7945758.40B/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 26542080/525832518 [00:01<00:50, 9838736.93B/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 30856192/525832518 [00:01<00:38, 12731153.38B/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 35869696/525832518 [00:01<00:30, 15991860.04B/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 40878080/525832518 [00:01<00:24, 20095532.13B/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▊         | 44722176/525832518 [00:01<00:20, 23123270.24B/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 48501760/525832518 [00:01<00:18, 25765264.50B/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 53449728/525832518 [00:01<00:15, 30091596.58B/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 57515008/525832518 [00:01<00:14, 31860216.01B/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 61468672/525832518 [00:02<00:14, 32834802.74B/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 66114560/525832518 [00:02<00:13, 34379921.91B/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▎        | 71128064/525832518 [00:02<00:12, 35833301.03B/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 76174336/525832518 [00:02<00:12, 36986372.13B/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 80859136/525832518 [00:02<00:11, 39478427.26B/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 85005312/525832518 [00:02<00:11, 38717206.58B/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 89019392/525832518 [00:02<00:11, 37928482.81B/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 93639680/525832518 [00:02<00:11, 38186385.86B/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 98685952/525832518 [00:03<00:11, 38718423.14B/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 103618560/525832518 [00:03<00:10, 41388393.24B/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 107845632/525832518 [00:03<00:10, 39935946.98B/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██▏       | 111911936/525832518 [00:03<00:10, 38979227.29B/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 116462592/525832518 [00:03<00:10, 38832645.26B/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 120632320/525832518 [00:03<00:10, 39649012.24B/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▎       | 124628992/525832518 [00:03<00:10, 39333194.93B/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 128979968/525832518 [00:03<00:10, 39177738.56B/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 133793792/525832518 [00:03<00:09, 41492566.80B/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 137992192/525832518 [00:04<00:09, 40197170.72B/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 142055424/525832518 [00:04<00:09, 39074912.58B/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 146544640/525832518 [00:04<00:09, 40653418.43B/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▊       | 150652928/525832518 [00:04<00:09, 39518636.23B/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 154641408/525832518 [00:04<00:09, 38900570.85B/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 159397888/525832518 [00:04<00:08, 41146204.59B/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 163567616/525832518 [00:04<00:08, 40880459.84B/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 167694336/525832518 [00:04<00:08, 39926749.67B/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 172486656/525832518 [00:04<00:08, 42029965.47B/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 176742400/525832518 [00:04<00:08, 40659303.35B/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 180854784/525832518 [00:05<00:08, 39926280.77B/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 185472000/525832518 [00:05<00:08, 39875379.31B/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 190193664/525832518 [00:05<00:08, 41825864.95B/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 194418688/525832518 [00:05<00:08, 40753054.90B/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 198530048/525832518 [00:05<00:08, 39755527.63B/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▊      | 203232256/525832518 [00:05<00:08, 39285598.33B/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|███▉      | 208147456/525832518 [00:05<00:07, 41800708.77B/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 212387840/525832518 [00:05<00:07, 41209482.95B/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 216749056/525832518 [00:05<00:07, 40803134.50B/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 221956096/525832518 [00:06<00:06, 43634269.23B/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 226397184/525832518 [00:06<00:06, 42817434.55B/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 230736896/525832518 [00:06<00:07, 41551471.63B/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 235052032/525832518 [00:06<00:06, 42016950.83B/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 239289344/525832518 [00:06<00:06, 41861488.87B/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 243569664/525832518 [00:06<00:06, 40981707.83B/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 248866816/525832518 [00:06<00:06, 43963403.78B/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 253339648/525832518 [00:06<00:06, 42684251.93B/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 257670144/525832518 [00:06<00:06, 41933512.95B/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 262493184/525832518 [00:07<00:06, 43633646.24B/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 266906624/525832518 [00:07<00:06, 42744919.56B/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 271220736/525832518 [00:07<00:06, 42108839.99B/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 275895296/525832518 [00:07<00:05, 43399871.55B/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 280266752/525832518 [00:07<00:05, 42853540.53B/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 284972032/525832518 [00:07<00:05, 43079158.83B/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 289740800/525832518 [00:07<00:05, 44364817.23B/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 294199296/525832518 [00:07<00:05, 43571120.87B/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 298849280/525832518 [00:07<00:05, 43326745.29B/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 303576064/525832518 [00:07<00:05, 44437054.22B/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▊    | 308036608/525832518 [00:08<00:04, 43829972.57B/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 313086976/525832518 [00:08<00:04, 44385454.71B/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 318033920/525832518 [00:08<00:04, 45797238.43B/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████▏   | 322632704/525832518 [00:08<00:04, 45188510.96B/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 327652352/525832518 [00:08<00:04, 45267510.60B/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 332583936/525832518 [00:08<00:04, 46410252.56B/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 337240064/525832518 [00:08<00:04, 44951056.50B/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 341859328/525832518 [00:08<00:04, 44760712.83B/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 346549248/525832518 [00:08<00:03, 45372811.89B/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 351098880/525832518 [00:08<00:03, 44496132.99B/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 355740672/525832518 [00:09<00:03, 43953127.53B/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▊   | 360655872/525832518 [00:09<00:03, 45393509.69B/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 365214720/525832518 [00:09<00:03, 44977845.34B/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 370173952/525832518 [00:09<00:03, 46267313.05B/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████▏  | 374860800/525832518 [00:09<00:03, 46176646.61B/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 379492352/525832518 [00:09<00:03, 45421582.40B/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 384516096/525832518 [00:09<00:03, 46764758.59B/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 389211136/525832518 [00:09<00:02, 45999560.72B/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 393827328/525832518 [00:09<00:02, 45395355.80B/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 398759936/525832518 [00:10<00:02, 46502585.47B/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 403426304/525832518 [00:10<00:02, 46042970.97B/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 408392704/525832518 [00:10<00:02, 47071940.13B/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▊  | 413114368/525832518 [00:10<00:02, 46936483.43B/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 417818624/525832518 [00:10<00:02, 45955665.70B/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 422828032/525832518 [00:10<00:02, 47122725.91B/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 427555840/525832518 [00:10<00:02, 46824269.83B/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 432249856/525832518 [00:10<00:02, 46018803.52B/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 437024768/525832518 [00:10<00:01, 46524307.35B/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 441687040/525832518 [00:10<00:01, 45680304.36B/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 446571520/525832518 [00:11<00:01, 45697372.54B/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 451356672/525832518 [00:11<00:01, 46316411.97B/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 455995392/525832518 [00:11<00:01, 45909702.80B/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 460855296/525832518 [00:11<00:01, 46682844.48B/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▊ | 465559552/525832518 [00:11<00:01, 46582144.30B/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 470222848/525832518 [00:11<00:01, 45058688.22B/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 474743808/525832518 [00:11<00:01, 44787437.20B/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 479314944/525832518 [00:11<00:01, 45060077.55B/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 484063232/525832518 [00:11<00:00, 45757790.88B/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 488777728/525832518 [00:11<00:00, 46163787.35B/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 493401088/525832518 [00:12<00:00, 45383496.09B/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 498259968/525832518 [00:12<00:00, 46285288.17B/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 502898688/525832518 [00:12<00:00, 46101986.68B/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 507515904/525832518 [00:12<00:00, 45587995.55B/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 512481280/525832518 [00:12<00:00, 46721375.83B/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 517165056/525832518 [00:12<00:00, 46194503.72B/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 521837568/525832518 [00:12<00:00, 46352136.02B/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 id  ... landmark_id\n",
            "0  6e158a47eb2ca3f6  ...      142820\n",
            "1  202cd79556f30760  ...      104169\n",
            "2  3ad87684c99c06e1  ...       37914\n",
            "3  e7f70e9c61e66af3  ...      102140\n",
            "4  4072182eddd0100e  ...        2474\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "(4132914, 3)\n",
            "Number of classes 203094\n",
            "Total number of valid classes: 52583\n",
            "Total number of valid examples: 3116604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|██████████| 525832518/525832518 [00:30<00:00, 46352136.02B/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['.config', '__pycache__', 'test.csv', 'categories_places365.txt', 'places365_class_index.json', 'vgg16-hybrid1365.png', 'my_model.h5', 'categories_places365_extended.csv', 'validation', 'places_utils.py', 'train.csv', 'vgg16-places365.png', 'vgg16_places_365.py', 'categories_hybrid1365.txt', 'vgg16_hybrid_places_1365.py', 'sample_data']\n",
            "total: 6212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 192, 192, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 198, 198, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 96, 96, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 96, 96, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 96, 96, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 98, 98, 64)   0           activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 48, 48, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 48, 48, 64)   4160        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 48, 48, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 48, 48, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 48, 48, 64)   36928       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 48, 48, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 48, 48, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 48, 48, 256)  16640       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 48, 48, 256)  16640       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 48, 48, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 48, 48, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 48, 48, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 48, 48, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 48, 48, 64)   16448       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 48, 48, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 48, 48, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 48, 48, 64)   36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 48, 48, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 48, 48, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 48, 48, 256)  16640       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 48, 48, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 48, 48, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 48, 48, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 48, 48, 64)   16448       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 48, 48, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 48, 48, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 48, 48, 64)   36928       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 48, 48, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 48, 48, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 48, 48, 256)  16640       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 48, 48, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 48, 48, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 48, 48, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 24, 24, 128)  32896       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 24, 24, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 24, 24, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 24, 24, 512)  131584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 24, 24, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 24, 24, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 24, 24, 512)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 24, 24, 128)  65664       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 24, 24, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 24, 24, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 24, 24, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 24, 24, 512)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 24, 24, 128)  65664       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 24, 24, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 24, 24, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 24, 24, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 24, 24, 512)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 24, 24, 128)  65664       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 24, 24, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 24, 24, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 24, 24, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 24, 24, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 256)  131328      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 1024) 525312      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 12, 12, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 1024) 0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 12, 12, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 1024) 0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 12, 12, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 1024) 0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 12, 12, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 1024) 0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 12, 12, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 1024) 0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 12, 12, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 12, 12, 1024) 0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 512)    524800      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 512)    2359808     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 2048)   1050624     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 2048)   2099200     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 6, 6, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 512)    1049088     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 512)    2359808     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 2048)   1050624     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 6, 6, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 6, 6, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 512)    1049088     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 6, 6, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 512)    2359808     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 6, 6, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 2048)   1050624     activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 6, 6, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 6, 6, 2048)   0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_2 (GlobalM (None, 2048)         0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 52583)        107742567   global_max_pooling2d_2[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 131,330,279\n",
            "Trainable params: 131,277,159\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "loaded model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/1998812 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  2%|▏         | 34816/1998812 [00:00<00:06, 282967.72B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 11%|█▏        | 226304/1998812 [00:00<00:04, 373697.38B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 1998812/1998812 [00:00<00:00, 4321307.03B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 id\n",
            "0  00016575233bc956\n",
            "1  0001aadbcd8cb923\n",
            "2  0002c06b2440a5f9\n",
            "3  0002eb1ee5a5a6b2\n",
            "4  000594dad986513e\n",
            "117577\n",
            "<tarfile.TarFile object at 0x7f684f249c50> 5879 5879\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "<tarfile.TarFile object at 0x7f683ba1d898> 5879 5879\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}