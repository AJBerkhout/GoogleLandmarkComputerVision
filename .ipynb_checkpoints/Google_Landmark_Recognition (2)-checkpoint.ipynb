{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "btbYdZim7AtA",
    "outputId": "4c0e9ab7-4f53-48f6-8a01-fc2fb98d928d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-Ama-IecGIds",
    "outputId": "e99b4d8d-4de0-4092-8c7e-6458680c23d7"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import keras\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import Layer\n",
    "from keras import regularizers\n",
    "from keras.engine.topology import Input\n",
    "from keras.layers import Activation, Add, BatchNormalization, Concatenate, Conv2D, Dense, Flatten, GlobalMaxPooling2D, \\\n",
    "    GlobalAveragePooling2D, Lambda, MaxPooling2D, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from collections import Counter\n",
    "from shutil import copyfile\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import cv2\n",
    "from keras.utils import Sequence\n",
    "import cv2\n",
    "import urllib\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "from keras.models import load_model\n",
    "import os\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "from vgg16_places_365 import VGG16_Places365\n",
    "\n",
    "\n",
    "def check_size(url):\n",
    "    \"\"\"\n",
    "    Helper method to check the size of the file from the url\n",
    "    \"\"\"\n",
    "    r = requests.get(url, stream=True)\n",
    "    return int(r.headers['Content-Length'])\n",
    "\n",
    "\n",
    "def download_file(url, filename, bar=True):\n",
    "    \"\"\"\n",
    "    Helper method handling downloading large files from `url` to `filename`. Returns a pointer to `filename`.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chunkSize = 1024\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(filename, 'wb') as f:\n",
    "            if bar:\n",
    "                pbar = tqdm(unit=\"B\", total=int(r.headers['Content-Length']))\n",
    "            for chunk in r.iter_content(chunk_size=chunkSize):\n",
    "                if chunk:  # filter out keep-alive new chunks\n",
    "                    if bar:\n",
    "                        pbar.update(len(chunk))\n",
    "                    f.write(chunk)\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "\n",
    "def download_image_cv2_urllib(url):\n",
    "    \"\"\"\n",
    "    Modifying the url to download the 360p or 720p version actually slows it down.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = urllib.request.urlopen(url)\n",
    "        foo = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        foo = cv2.imdecode(foo, cv2.IMREAD_COLOR)\n",
    "        foo = cv2.resize(foo, (192, 192), interpolation=cv2.INTER_AREA)\n",
    "        foo = cv2.cvtColor(foo, cv2.COLOR_BGR2RGB)\n",
    "        return foo\n",
    "    except:\n",
    "        return np.array([])\n",
    "    \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def accuracy_class(y_true, y_pred):\n",
    "    true = K.argmax(y_true, axis=1)\n",
    "    pred = K.argmax(y_pred, axis=1)\n",
    "    matches = K.equal(true, pred)\n",
    "    return K.mean(matches)\n",
    "\n",
    "\n",
    "def accuracy_class_numpy(y_true, y_pred):\n",
    "    true = np.argmax(y_true, axis=1)\n",
    "    pred = np.argmax(y_pred, axis=1)\n",
    "    matches = true == pred\n",
    "    return np.mean(matches)\n",
    "\n",
    "\n",
    "def getConfidence(y_pred):\n",
    "    y_pred_max = np.reshape(np.amax(y_pred, axis=1), (y_pred.shape[0], 1))\n",
    "\n",
    "    top5 = np.zeros((y_pred.shape[0], 5))\n",
    "    max_indices = np.argsort(y_pred, axis=1)[:, ::-1][:, :5]\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        top5[i, :] = y_pred[i, max_indices[i, :]]\n",
    "    diff = y_pred_max - top5\n",
    "    weights = np.array([[0., 0.35, 0.28, 0.22, 0.15]])\n",
    "    weighted_diffs = diff * weights\n",
    "    return np.sum(weighted_diffs, axis=1)\n",
    "\n",
    "\n",
    "def getOrder(y_pred):\n",
    "    summ = getConfidence(y_pred)\n",
    "    summ_indices = np.argsort(summ)[::-1]\n",
    "    return summ_indices\n",
    "\n",
    "\n",
    "def MAP_numpy(y_true, y_pred):\n",
    "    true = np.argmax(y_true, axis=1)\n",
    "    pred = np.argmax(y_pred, axis=1)\n",
    "    matches = true == pred\n",
    "\n",
    "    order = getOrder(y_pred)\n",
    "    orderedMatches = matches[order]\n",
    "\n",
    "    correct = 0.\n",
    "    summ = 0.\n",
    "    for i in range(y_true.shape[0]):\n",
    "        correct += int(orderedMatches[i])\n",
    "        summ += (correct / (i + 1)) * int(orderedMatches[i])\n",
    "    return summ / y_true.shape[0]\n",
    "\n",
    "\n",
    "def validateMAP(model, valid_x, valid_y):\n",
    "    \"\"\"\n",
    "    :param model: the model to use\n",
    "    :param valid_x: numpy array of validation images\n",
    "    :param valid_y: list of landmarks of the validation images\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    N = valid_x.shape[0]\n",
    "    batchsize = 1000\n",
    "    conf_list = []\n",
    "    y_pred_list = []\n",
    "    validM = N // batchsize + int(N % batchsize > 0)\n",
    "    for i in range(validM):\n",
    "        preds = model.predict(valid_x[i * batchsize:min(N, (i + 1) * batchsize), :, :, :])\n",
    "        conf = list(np.amax(preds, axis=1))\n",
    "        conf_list.extend(conf)\n",
    "        y_pred = list(np.argmax(preds, axis=1))\n",
    "        y_pred_list.extend(y_pred)\n",
    "\n",
    "    matches = list(np.array(y_pred_list) == np.array(valid_y))\n",
    "\n",
    "    order = list(np.argsort(conf_list)[::-1])\n",
    "    orderedMatches = [matches[o] for o in order]\n",
    "\n",
    "    correct = 0.\n",
    "    summ = 0.\n",
    "    for i in range(len(orderedMatches)):\n",
    "        correct += int(orderedMatches[i])\n",
    "        summ += (correct / (i + 1)) * int(orderedMatches[i])\n",
    "\n",
    "    print(np.sum(matches))\n",
    "    print(correct)\n",
    "    print(summ / len(orderedMatches))\n",
    "\n",
    "\n",
    "class DataGen(Sequence):\n",
    "    \"\"\"\n",
    "    This generator downloads one tar file at each epoch. Extracts and selects the valid images from it to\n",
    "    form batches. And after the epoch is complete, deletes the files to free up space.\n",
    "    \"\"\"\n",
    "    def __init__(self, valid_ids_dict, num_classes, start=10, batch_size=128, steps=10, verbose=1):\n",
    "\n",
    "        self.valid_ids_dict = valid_ids_dict # dict of image ids to landmarks {image_id: landmark_id}\n",
    "        self.NUM_CLASSES = num_classes # number of valid classes to consider\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = steps # should be equal to the number of epochs\n",
    "        self.images = []\n",
    "        self.landmarks = []\n",
    "        self.tar_idx = start\n",
    "        self.epoch_init()\n",
    "\n",
    "    def epoch_init(self):\n",
    "        self.all_images = []\n",
    "        self.all_landmarks = []\n",
    "\n",
    "        if self.tar_idx < 10:\n",
    "            tarfilestr = \"00\" + str(self.tar_idx)\n",
    "        elif self.tar_idx < 100:\n",
    "            tarfilestr = \"0\" + str(self.tar_idx)\n",
    "        else:\n",
    "            tarfilestr = str(self.tar_idx)\n",
    "\n",
    "        download_file(\"https://s3.amazonaws.com/google-landmark/train/images_{}.tar\".format(tarfilestr), \"images.tar\",\n",
    "                      bar=False)\n",
    "        tar = tarfile.open('images.tar')\n",
    "        tar.extractall(\"imagesfolder\")\n",
    "        tar.close()\n",
    "\n",
    "        self.total = self.pickfiles(\"imagesfolder\")\n",
    "        self.tar_idx += 1\n",
    "        print(\"tar\", self.tar_idx - 1, \"total:\", self.total)\n",
    "\n",
    "    def pickfiles(self, dirr):\n",
    "        count = 0\n",
    "        for f in os.listdir(dirr):\n",
    "            if os.path.isfile(dirr + \"/\" + f):\n",
    "                if f[:-4] in self.valid_ids_dict:\n",
    "                    self.all_images.append(dirr + \"/\" + f)\n",
    "                    self.all_landmarks.append(self.valid_ids_dict[f[:-4]])\n",
    "                    count += 1\n",
    "            else:\n",
    "                count += self.pickfiles(dirr + \"/\" + f)\n",
    "        return count\n",
    "\n",
    "    def normalize(self, data):\n",
    "        return data / 255 - 0.5\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path_list = self.all_images[index * self.batch_size:min(self.total, (index + 1)) * self.batch_size]\n",
    "        class_list = self.all_landmarks[index * self.batch_size:min(self.total, (index + 1)) * self.batch_size]\n",
    "\n",
    "        if len(image_path_list) == 0:\n",
    "            image_path_list = self.all_images[:self.batch_size]\n",
    "            class_list = self.all_landmarks[:self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        y_list = []\n",
    "        for ix in range(len(image_path_list)):\n",
    "            try:\n",
    "                image_path = image_path_list[ix]\n",
    "                im = cv2.imread(image_path)\n",
    "                im = cv2.resize(im, (192, 192), interpolation=cv2.INTER_AREA)\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                if im.shape == (192, 192, 3):\n",
    "                    images.append(im)\n",
    "                    y_list.append(class_list[ix])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        x = np.array(images)\n",
    "        y = np.zeros((len(y_list), self.NUM_CLASSES))\n",
    "\n",
    "        for i in range(len(y_list)):\n",
    "            y[i, y_list[i]] = 1.\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.steps -= 1\n",
    "        os.unlink(\"images.tar\")\n",
    "        shutil.rmtree(\"imagesfolder\")\n",
    "        if self.steps > 0:\n",
    "            self.epoch_init()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total // self.batch_size + int(self.total % self.batch_size > 0)\n",
    "\n",
    "\n",
    "class DataGenURLVersion(Sequence):\n",
    "    \"\"\"';'\n",
    "    This generator uses the image urls from the train dataset to form batches\n",
    "    and downloads each image individually. It will be approx 10 times slower than above version.\n",
    "    \"\"\"\n",
    "    def __init__(self, valid_urls_dict, num_classes, data, batch_size=24, verbose=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.data_urls = data\n",
    "        self.NUM_CLASSES = num_classes # number of classes\n",
    "        self.valid_urls_dict = valid_urls_dict # dict of url and corresponding landmark {image_url: landmark}\n",
    "\n",
    "    def normalize(self, data):\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_urls = random.sample(self.data_urls, self.batch_size)\n",
    "\n",
    "        output = []\n",
    "        y_classes = []\n",
    "        for url in batch_urls:\n",
    "            im = download_image_cv2_urllib(url)\n",
    "            if im.size != 0:\n",
    "                output.append(im)\n",
    "                y_classes.append(self.valid_urls_dict[url.split(\"/\")[-1]])\n",
    "\n",
    "        x = np.array(output)\n",
    "        y = np.zeros((len(output), self.NUM_CLASSES))\n",
    "\n",
    "        for i in range(len(y_classes)):\n",
    "            y[i, y_classes[i]] = 1.\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(valid_urls_list) // self.batch_size\n",
    "        return 10\n",
    "\n",
    "    \n",
    "def isImageLandmark(categories, conf, label):\n",
    "  index = 0 \n",
    "  for (i, c) in enumerate(categories):\n",
    "      if label in c:\n",
    "          index = i\n",
    "\n",
    "  MIN_CONF = 0.7\n",
    "\n",
    "  if conf < MIN_CONF:\n",
    "      return True\n",
    "    \n",
    "  for c in ['warplane', 'coil', 'missile', 'conch', 'gar', 'tank',\n",
    "              'schooner', 'book jacket', 'scabbard', 'aircraft carrier',\n",
    "              'school bus', 'space shuttle', 'cannon',\n",
    "              'trilobite', 'tow truck', 'submarine', 'pickup', 'amphibian',\n",
    "              'marmot', 'mushroom', 'shield', 'French loaf',\n",
    "              'poncho', 'warthog']:\n",
    "        if label.startswith(c + ','):\n",
    "            return False\n",
    "  \n",
    "  \n",
    "\n",
    "  if index < 400:\n",
    "        return False\n",
    "\n",
    "  if index >= 985:\n",
    "        return False\n",
    "\n",
    "  return True\n",
    "\n",
    "# ------------------------------ form the dataset ------------------------------ #\n",
    "\n",
    "download_file(\"https://s3.amazonaws.com/google-landmark/metadata/train.csv\", \"train.csv\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "print(\"Number of classes {}\".format(len(train.landmark_id.unique())))\n",
    "\n",
    "\n",
    "\n",
    "NUM_THRESHOLD = 20\n",
    "\n",
    "counts = dict(Counter(train['landmark_id']))\n",
    "landmarks_dict = {x:[] for x in train.landmark_id.unique() if counts[x] >= NUM_THRESHOLD and x != 138982}\n",
    "NUM_CLASSES = len(landmarks_dict)\n",
    "print(\"Total number of valid classes: {}\".format(NUM_CLASSES))\n",
    "\n",
    "i = 0\n",
    "landmark_to_idx = {}\n",
    "idx_to_landmark = []\n",
    "for k in landmarks_dict:\n",
    "    landmark_to_idx[k] = i\n",
    "    idx_to_landmark.append(k)\n",
    "    i += 1\n",
    "\n",
    "all_ids = train['id'].tolist()\n",
    "all_landmarks = train['landmark_id'].tolist()\n",
    "valid_ids_dict = {x[0].split(\"/\")[-1]:landmark_to_idx[x[1]] for x in zip(all_ids, all_landmarks) if x[1] in landmarks_dict}\n",
    "valid_ids_list = [x[0] for x in zip(all_ids, all_landmarks) if x[1] in landmarks_dict]\n",
    "\n",
    "NUM_EXAMPLES = len(valid_ids_list)\n",
    "print(\"Total number of valid examples: {}\".format(NUM_EXAMPLES))\n",
    "\n",
    "\n",
    "# ------------------------------------- validation ------------------------------------------------- #\n",
    "\n",
    "download_file(\"https://s3.amazonaws.com/google-landmark/train/images_001.tar\", \"validation.tar\", bar=False)\n",
    "tar = tarfile.open('validation.tar')\n",
    "tar.extractall(\"validation\")\n",
    "tar.close()\n",
    "\n",
    "os.unlink(\"validation.tar\")\n",
    "\n",
    "print(os.listdir())\n",
    "\n",
    "validation_images_paths = []\n",
    "validation_landmarks = []\n",
    "\n",
    "\n",
    "def pickfiles(dirr):\n",
    "    count = 0\n",
    "    for f in os.listdir(dirr):\n",
    "        if os.path.isfile(dirr + \"/\" + f):\n",
    "            if f[:-4] in valid_ids_dict:\n",
    "                validation_images_paths.append(dirr + \"/\" + f)\n",
    "                validation_landmarks.append(valid_ids_dict[f[:-4]])\n",
    "                count += 1\n",
    "        else:\n",
    "            count += pickfiles(dirr + \"/\" + f)\n",
    "    return count\n",
    "\n",
    "\n",
    "total = pickfiles(\"validation\")\n",
    "print(\"total:\", total)\n",
    "\n",
    "validation_images = []\n",
    "\n",
    "for image_path in validation_images_paths:\n",
    "    im = cv2.imread(image_path)\n",
    "    im = cv2.resize(im, (192, 192), interpolation=cv2.INTER_AREA)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    validation_images.append(im)\n",
    "\n",
    "valid_x = np.array(validation_images)\n",
    "valid_y = np.zeros((len(validation_landmarks), NUM_CLASSES))\n",
    "\n",
    "for i in range(len(validation_landmarks)):\n",
    "    valid_y[i, validation_landmarks[i]] = 1.\n",
    "\n",
    "shutil.rmtree(\"validation\")\n",
    "del validation_images\n",
    "\n",
    "# ------------------------------------ model ----------------------------------------- #\n",
    "\n",
    "res = ResNet50(include_top=False, weights='imagenet', input_shape=(192, 192, 3))\n",
    "\n",
    "# making all the layers trainable\n",
    "for layer in res.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "out = GlobalMaxPooling2D()(res.output)\n",
    "out = Dense(NUM_CLASSES, activation='softmax')(out)\n",
    "model = Model(res.input, out)\n",
    "model.summary()\n",
    "\n",
    "# ----------------------------------- training ---------------------------------------- #\n",
    "\n",
    "# EPOCHS = 170\n",
    "# opt = Adam(0.0002)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
    "# model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=10, batch_size=64,steps=EPOCHS),\n",
    "#                    epochs=EPOCHS,\n",
    "#                    validation_data = [valid_x, valid_y],\n",
    "#                    use_multiprocessing=True,\n",
    "#                    workers=8,\n",
    "#                    verbose=2)\n",
    "\n",
    "# model.save('my_model3.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# print(\"model saved\")\n",
    "\n",
    "# model = load_model(F'/content/drive/My Drive/my_model3.h5', custom_objects={\n",
    "#         \"accuracy_class\": accuracy_class\n",
    "#     })\n",
    "# print(\"loaded model\")\n",
    "\n",
    "# EPOCHS = 50\n",
    "# opt = Adam(0.0001)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
    "# model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=180, batch_size=48,steps=EPOCHS),\n",
    "#                     epochs=EPOCHS,\n",
    "#                     validation_data = [valid_x, valid_y],\n",
    "#                     use_multiprocessing=True,\n",
    "#                     workers=4,\n",
    "#                     verbose=2)\n",
    "\n",
    "# model.save(F'/content/drive/My Drive/my_model2.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# print(\"model saved\")\n",
    "\n",
    "# model = load_model(F'/content/drive/My Drive/my_model2.h5', custom_objects={\n",
    "#         \"accuracy_class\": accuracy_class\n",
    "#     })\n",
    "# print(\"loaded model\")\n",
    "\n",
    "# EPOCHS = 50\n",
    "# opt = Adam(0.0001)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
    "# model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=230, batch_size=48,steps=EPOCHS),\n",
    "#                     epochs=EPOCHS,\n",
    "#                     validation_data = [valid_x, valid_y],\n",
    "#                     use_multiprocessing=True,\n",
    "#                     workers=4,\n",
    "#                     verbose=2)\n",
    "\n",
    "# model.save(F'/content/drive/My Drive/my_model2.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# print(\"model saved\")\n",
    "\n",
    "# model = load_model(F'/content/drive/My Drive/my_model2.h5', custom_objects={\n",
    "#          \"accuracy_class\": accuracy_class\n",
    "#      })\n",
    "# print(\"loaded model\")\n",
    "\n",
    "# EPOCHS = 50\n",
    "# opt = Adam(0.0001)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
    "# model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=230, batch_size=48,steps=EPOCHS),\n",
    "#                     epochs=EPOCHS,\n",
    "#                     validation_data = [valid_x, valid_y],\n",
    "#                     use_multiprocessing=True,\n",
    "#                     workers=4,\n",
    "#                     verbose=2)\n",
    "\n",
    "# model.save(F'/content/drive/My Drive/my_model2.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# print(\"model saved\")\n",
    "\n",
    "\n",
    "# model = load_model(F'/content/drive/My Drive/my_model2.h5', custom_objects={\n",
    "#         \"accuracy_class\": accuracy_class\n",
    "#     })\n",
    "# print(\"loaded model\")\n",
    "\n",
    "# EPOCHS = 50\n",
    "# opt = Adam(0.00004)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
    "# model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=340, batch_size=48,steps=EPOCHS),\n",
    "#                     epochs=EPOCHS,\n",
    "#                     validation_data = [valid_x, valid_y],\n",
    "#                     use_multiprocessing=True,\n",
    "#                     workers=4,\n",
    "#                     verbose=2)\n",
    "\n",
    "# model.save(F'/content/drive/My Drive/my_model1.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# print(\"model saved\")\n",
    "\n",
    "# model = load_model(F'/content/drive/My Drive/my_model1.h5', custom_objects={\n",
    "#          \"accuracy_class\": accuracy_class\n",
    "#      })\n",
    "# print(\"loaded model\")\n",
    "\n",
    "# EPOCHS = 50\n",
    "# opt = Adam(0.00002)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
    "# model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=390, batch_size=48,steps=EPOCHS),\n",
    "#                     epochs=EPOCHS,\n",
    "#                     validation_data = [valid_x, valid_y],\n",
    "#                     use_multiprocessing=True,\n",
    "#                     workers=4,\n",
    "#                     verbose=2)\n",
    "\n",
    "# model.save(F'/content/drive/My Drive/my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# print(\"model saved\")\n",
    "\n",
    "# model = load_model(F'/content/drive/My Drive/my_model1.h5', custom_objects={\n",
    "#         \"accuracy_class\": accuracy_class\n",
    "#     })\n",
    "# print(\"loaded model\")\n",
    "\n",
    "# EPOCHS = 60\n",
    "# opt = Adam(0.00002)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\n",
    "# model.fit_generator(generator=DataGen(valid_ids_dict, NUM_CLASSES, start=440, batch_size=48,steps=EPOCHS),\n",
    "#                     epochs=EPOCHS,\n",
    "#                     validation_data = [valid_x, valid_y],\n",
    "#                     use_multiprocessing=True,\n",
    "#                     workers=4,\n",
    "#                     verbose=2)\n",
    "\n",
    "# # ------------------------------------------- GAP metric validation -------------------------------------- #\n",
    "\n",
    "# model.save(F'/content/drive/My Drive/my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# print(\"model saved\")\n",
    "# del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model(F'my_model (1).h5', custom_objects={\n",
    "        \"accuracy_class\": accuracy_class\n",
    "    })\n",
    "print(\"loaded model\")\n",
    "#gap = validateMAP()\n",
    "#print(gap)\n",
    "\n",
    "# ------------------------------------------- testset ------------------------------------------------- #\n",
    "\n",
    "download_file(\"https://s3.amazonaws.com/google-landmark/metadata/test.csv\", \"test.csv\")\n",
    "testdf = pd.read_csv(\"test.csv\")\n",
    "print(testdf.head())\n",
    "\n",
    "testids = testdf['id'].tolist()\n",
    "print(len(testids))\n",
    "\n",
    "# -------------------------------------------- prediction ------------------------------------------------ #\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import time\n",
    "\n",
    "tm = time.time()\n",
    "\n",
    "final_ids = []\n",
    "final_conf = []\n",
    "final_preds = []\n",
    "\n",
    "tar_images = []\n",
    "tar_ids = []\n",
    "    \n",
    "    \n",
    "def pickfiles(dirr):\n",
    "    count = 0\n",
    "    for f in os.listdir(dirr):\n",
    "        if os.path.isfile(dirr + \"/\" + f):\n",
    "            tar_images.append(dirr + \"/\" + f)\n",
    "            tar_ids.append(f[:-4])\n",
    "            count += 1\n",
    "        else:\n",
    "            count += pickfiles(dirr + \"/\" + f)\n",
    "    return count\n",
    "\n",
    "with open(F'imagenet1000.txt') as f:\n",
    "  imagenet = eval(f.read())\n",
    "\n",
    "discrim_model_2 = ResNet50(include_top=True, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "for tar in range(20):\n",
    "    if tar < 10:\n",
    "        tar_id = \"00\" + str(tar)\n",
    "    else:\n",
    "        tar_id = \"0\" + str(tar)\n",
    "\n",
    "    tar_images = []\n",
    "    tar_ids = []\n",
    "\n",
    "    download_file(\"https://s3.amazonaws.com/google-landmark/test/images_{}.tar\".format(tar_id), \"images.tar\", bar=False)\n",
    "    tar = tarfile.open('images.tar')\n",
    "    tar.extractall(\"imagesfolder\")\n",
    "    tar.close()\n",
    "\n",
    "    os.unlink(\"images.tar\")\n",
    "\n",
    "    total = pickfiles(\"imagesfolder\")\n",
    "    print(tar, total, len(tar_ids))\n",
    "        \n",
    "    \n",
    "    N = total\n",
    "    batchsize = 1000\n",
    "    conf_list = []\n",
    "    y_pred_list = []\n",
    "    validM = N // batchsize + int(N % batchsize > 0)\n",
    "    \n",
    "    # Placeholders for predictions\n",
    "\n",
    "\n",
    "    # Places365 Model\n",
    "    # discrim_model = VGG16_Places365(weights='places')\n",
    "    \n",
    "    # class_information = pd.read_csv(F'/content/drive/My Drive/categories_places365_extended.csv')\n",
    "\n",
    "\n",
    "  \n",
    "    categories = list(imagenet.values())\n",
    "\n",
    "    topn = 5\n",
    "    \n",
    "    for i in range(validM):\n",
    "        temp = tar_images[i * batchsize:min(N, (i + 1) * batchsize)]\n",
    "        batch_images = []\n",
    "        batch_images_2 = []\n",
    "        for t in temp:\n",
    "            im = cv2.imread(t)\n",
    "            im = cv2.resize(im, (192, 192), interpolation=cv2.INTER_AREA)\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            batch_images.append(im)\n",
    "        for t in temp:\n",
    "            im = cv2.imread(t)\n",
    "            im = cv2.resize(im, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            batch_images_2.append(im)\n",
    "        p0, p1, p2 = [], [], []\n",
    "        isLandmark = []\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_images_2 = np.array(batch_images_2)\n",
    "        all_preds = discrim_model_2.predict(batch_images_2)\n",
    "        all_preds = decode_predictions(all_preds)\n",
    "        # Loop through all images\n",
    "        for (i, image) in enumerate(batch_images_2):\n",
    "    \n",
    "            # Predict Top N Image Classes\n",
    "            image = np.expand_dims(image, 0)\n",
    "            #topn_preds = np.argsort(discrim_model.predict(image)[0])[::-1][0:topn]\n",
    "            image_preds = all_preds[i]\n",
    "\n",
    "            images0 = image_preds[0]\n",
    "            images1 = image_preds[1]\n",
    "            images2 = image_preds[2]\n",
    "            images3 = image_preds[3]\n",
    "            num_landmark = 0\n",
    "            if (not isImageLandmark(categories, images0[2], images0[1])):\n",
    "                num_landmark += 1\n",
    "              \n",
    "            if (not isImageLandmark(categories, images1[2], images1[1])):\n",
    "                num_landmark += 1\n",
    "\n",
    "            if (not isImageLandmark(categories, images2[2], images2[1])):\n",
    "                num_landmark += 1\n",
    "          \n",
    "            # places0 = topn_preds[0]\n",
    "            # places1 = topn_preds[1]\n",
    "            # places2 = topn_preds[2]\n",
    "            # p0_landmark = class_information.loc[places0, ['landmark']][0]\n",
    "            # p1_landmark = class_information.loc[places1, ['landmark']][0]\n",
    "            # p2_landmark = class_information.loc[places2, ['landmark']][0]\n",
    "            # num_landmark = 0\n",
    "            # if (p0_landmark == 1): \n",
    "            #     num_landmark += 1\n",
    "            # if (p1_landmark == 1):\n",
    "            #     num_landmark += 1\n",
    "            # if (p2_landmark == 1): \n",
    "            #     num_landmark += 1\n",
    "            if(num_landmark >= 2):\n",
    "              isLandmark.append(True)\n",
    "            else:\n",
    "              isLandmark.append(False)\n",
    "            \n",
    "        \n",
    "        preds = model.predict(batch_images)\n",
    "        \n",
    "        conf = list(np.amax(preds, axis=1))\n",
    "        \n",
    "        \n",
    "        y_pred = list(np.argmax(preds, axis=1))\n",
    "        for (i, y) in enumerate(zip(y_pred)):\n",
    "          if(not isLandmark[i]):\n",
    "            conf[i] = ''\n",
    "            y_pred[i] = ''\n",
    "\n",
    "        conf_list.extend(conf)\n",
    "        y_pred_list.extend(y_pred)\n",
    "\n",
    "    final_preds.extend(y_pred_list)\n",
    "    final_conf.extend(conf_list)\n",
    "    final_ids.extend(tar_ids)\n",
    "    shutil.rmtree(\"imagesfolder\")\n",
    "\n",
    "print(\"time\", time.time() - tm)\n",
    "print(len(final_preds))\n",
    "\n",
    "\n",
    "# --------------------------------------- submission -------------------------------------- #\n",
    "\n",
    "out = []\n",
    "for i in range(len(final_preds)):\n",
    "    idx = final_preds[i]\n",
    "    out.append(str(idx_to_landmark[idx]) + \" \" + str(round(final_conf[i], 10)))\n",
    "\n",
    "print(out[:5])\n",
    "\n",
    "outdf = pd.DataFrame({\"id\": final_ids, \"landmarks\": out})\n",
    "print(outdf.head())\n",
    "\n",
    "outdf.to_csv(F\"submissions.csv\", index=False)\n",
    "\n",
    "# ---------------------------------------- the end ----------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "Google Landmark Recognition",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
